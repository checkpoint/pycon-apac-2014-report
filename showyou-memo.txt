PyconAPAC2014(台北) 訪問記　メモ

宵です。

Day 0　台北まで
前回は東京で業務をこなしたあと、その足で成田から台北まで向かいました。
今回は直前まで松山で行われました人工知能学会に参加していたため、関西空港から台北に向かいました。

Day 1

・ホテル(台北市内)から会場へ

昨年は清水川さん、鈴木たかのりさんと共にタクシーで会場に向かいました。
今回は地下鉄の乗り場やタクシーの使い方も把握したのと、それぞれ別のホテルに泊まっていましたため、地下鉄＋タクシーで向かいました。

台北にもEasyCardという日本で言うSuicaに相当するカードがありましたので、それにチャージして使っていきました。このカードを使うと若干運賃が安くなります。尤も地下鉄で台北から会場近くまで移動しても30NT$(1NT$=3.5円程度なので110円程度)と日本に比べると安いです。

大体台北駅から地下鉄、タクシーと乗り継いで40分くらいで会場まで着きます。昨年同様タクシーの運転手さんに英語で行き先を伝えても伝わらないので、建物名(漢字)と住所を携帯にメモして運転手さんに見せました。

・会場

まず受付ですが、去年と幾つか変わっており、結構混乱してました。受付番号が二日前にリマインダーメールとして届いたのですが、今回の受付は受付番号ではなく電話番号の下3桁でレーン分けされており、しかも510番以降の人の受付が去年と別の場所にあったため、わかりにくかったです。自分は受付番号も電話番号も後半の番号で去年の受付の場所に番号がなかったため、係りの人に英語で聞いて別の受付に移動したのでよかったのですが、わからずに並んであとで「違う」とか言われてたら残念だったでしょう。実際受付で怒ってるおじさんもいました。

カンファレンスの値段ですが、昨年より少し上がり2,290NT$になっていました。その代わり今回はパンフレットがフルカラーの冊子になり、おやつの時間にスイーツが振舞われました。その代わり1日目の夜に無料の食事会はありませんでした。<s>2290NT$と見ると台湾の物価としては高いですが、ノベルティとか朝食とか出ないのに24000円する人工知能学会に比べたら大分マシでしょう</s>


・Keynote Speech: Wes McKinney氏
今回の基調講演は、データ構造フレームワークpandasを作り、Python for Data Analysisを出版されたWes McKinney氏によるものでした。
話の流れとしては、Business Intelligence, Bussiness Analysis, ETL(Extract, Transform, Load。データの抽出、変換、加工のこと), 並びにPython用データサイエンス向けのカンファレンスPyDataの説明から始まり、次に pandasの利点と欠点、最後にご自身の会社で作成されているdatapad(http://datapad.io)というBIツールの説明の順で話が進んでいきました。datapadはサンフランシスコにある会社なのでTreasureDataとも競合するんじゃないかと思い、「TreasureDataはどうよ？」と質問しました。しかし「名前は知ってるがどんな会社か把握してない」という感じのことを返されました。

・セッション
前回は３〜４個ほどデータサイエンス的なセッションがありましたが、今回は1日目のセッションの一つが全部Scipyになっていました。それ以外にもデータ処理系のセッションが幾つかありました。というかバッティングしてて見れないのもありました。

　・PySpark
SparkはHadoopのMapReduceの様な並列計算エンジンで、MapReduceよりも10倍以上早いと言われるフレームワークです。さらにSparkはチュートリアルがPythonとScalaユーザ向けに書かれており、JavaでMapReduce書くよりも気軽にかけるようになっています。ただし途中の計算データは全部メモリ上展開されるため、メモリを思いっきり食います。

この発表ではYahoo Taiwanの方がSparkの話、利点とPythonからの使い方、さらにMovie Lensを使った例について語っていきました。
セッションの後に筆者が本人に聞いたところ、実際に使ってる環境では、用途ごとに1台あたりメモリを40GB~100GB程度積んでるとのことでした。


　・Hacking Models With Python
このセッションでは線形回帰の問題をScipyの二乗誤差最小化で解くことを例に挙げて、データだけでなくデータの見方、すなわちモデリングでも結果が変わってしまうことを語っていました。またこの手の問題では性能と正確さが天秤にかけられるといったことも述べられていました。

　・TextBlob: Text Analytics for Humans
この発表はScipyの発表ではありませんが、nltkを使って文章の分割、感情分析、句構造情報の付与などの説明がされていました。

　・Data Analysis in Python
このセッションはAnalysisとついてはいましたが、実際はnumpyのndarrayやpandasのdataframeの紹介程度で終わっていました。レジュメの方ではもう少し踏み込んだ話があったようなので残念でした。

・Keynote Speech:Python for scientist
この基調講演ではひたすらipython notebookを使っていろんなものを表示していました。特にD3.jsと絡めてPlot内容をインタラクティブに操作できるあたりがよかったです。話によれば、クイズで賞金王をとった人工頭脳、IBMのワトソンもipython notebookで対話してたようです。

・LT
今回は5分間の通常のLightning Talkとは別にFastest Lightning Talkという2分のLTが設けられました。当日の昼まで申し込み可能だったので、筆者も登録してみました。

2分ということもあったのでトピックを一つに絞って短めのものにして早めに切り上げたのですが、2分間ずっと喋らないといけないと言われ、そのあと細かな自己紹介をしていました。

なお通常のLTの方ですが、MidiキーボードとPygameあたりをつないで、Let it beのイントロを引いたら画面が変わるのがとてもおもしろかったです。


・1日目の後
今回は夕食がなかったため、日本人数人で開場前の旅館(昨年泊まったホテルです)の中華料理屋で食事を取りました。
今回のPycon APACの事を話していましたが、やはりみなさんScipyやデータ解析系のセッションが日本では無いことを気にしていました(応募はかけているのですが、日本ではなかなか応募が来ないようです)。

Day 2

・Keynote speech: ジェシカ・マッケラー
ジェシカは、様々な場所で使われているpythonについての講演を行いました。低いとこでは海底、高いとこでは宇宙ステーションでの利用例を紹介していました。

・Session
　・Async
　　ここでは客がピザを注文してから焼きあがるのを待つのと、板前におまかせと言って勝手に出てくる寿司を受け取る例をだして、同期/非同期の説明を行っていました。またC10K問題(クライアントが1万台のオーダーになったとき処理が捌ききれなく問題)にも触れ、最後にpythonでの非同期通信の方法として、twisted, tornedoに、さらにpython3.4から標準搭載となったasincioについての説明を行っていました。

 　・Searchable Knowledge Base
 　ここでは手順を事前にgithubに公開した上でQ&Aサイトの作り方の説明を行っていました。内部でdjango, solrが使われてるようです。

 　・How to Integrate Python into a Scala Stack to Build Realtime Model
 　ここではScala/Javaで組まれてるシステムからpythonを呼び出す方法の説明を行っていました。方法としてjythonを使う、thriftを使う、REST形式で呼び出す等挙げられてましたがメッセージキュー方式が挙がっておらず、聴講者からメッセージキューはどうなんだと聞かれ見落としてたといった感じの回答をしていました(実際の質疑は中国語なので詳しい内容は把握してないのですが、発表者の雰囲気見た限り見落としてたようです)

 　・Recommender as an example
 　　このセッションは録画禁止だったので詳細は書きませんが、広告配信でCTR(クリック率),CVR(コンバージョン)を上げるための集計システムについての紹介を行ってました。

 　・Social Network
 　FacebookのOAuth経由APIを使って、イイネ！ボタン押したユーザ数とか友達ユーザクラスタの検出などを行ってました。実際にその場で実行しており、見ててとてもわかり易い発表でした。また発表中中国語(マンダリン)の単語分割器JIEBA(日本でいうとこのMeCabの単語分割部分のみってところ)の紹介があり、それを使ったツールも紹介されていました。日本人の私がそのツールを使ってもJIEBAによって漢字部分だけ抽出されていました。

 　・Socialite
 　集計、JOINに特化した分散環境言語、Socialiteの紹介をしていました。pythonから呼ぶことができ、文法はErlangのようでした。比較対象としてHadoop上で動くJiraphも挙げている部分が面白いと感じました。ただこの辺ってSparkもそうですがSQLに似た言語の方が好まれる感じもするのですが如何なんでしょうか。Hadoop(MapReduce)の場合Hive, Sparkの場合Shark, SparkSQLといったのがSQLライクな言語としてあります。

 ・全体を振り返って
 　これは去年も出した感想ですが、日本と違い数学系の発表が多いと感じました。一方でDjango等Web系フレームワークの話が少なめな感じでした。また、発表のスライドは講演者の言語に依らず英語で作成されており、中国語を知らない私でもスライドを見て理解できる感じでした。

 個人としての感想ですが、
 「スライドは英語で作る(日本語版も作成するのはあり)」
 「Scipyや計算系の応募を増やす」
 と言ったところが出来るといいと考えています。

